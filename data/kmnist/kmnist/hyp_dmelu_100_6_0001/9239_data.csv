,Model,Activation,Test accuracy,Test loss,Train accuracy,Train loss,Epoch,Learning rate,Weight decay,Neurons,Nlayers,Train hyperbolicities,Test hyperbolicities,Time
0,model_type.hyperbolic,activation.dmelu,0.74939996,0.78651416,0.7730456,0.72305006,0,0.0001,1e-05,100,6,,,44.09046220779419
1,model_type.hyperbolic,activation.dmelu,0.7802,0.6837573,0.88637275,0.36315098,1,0.0001,1e-05,100,6,,,85.63334059715271
2,model_type.hyperbolic,activation.dmelu,0.825,0.562544,0.91262007,0.28342384,2,0.0001,1e-05,100,6,,,130.81626319885254
3,model_type.hyperbolic,activation.dmelu,0.83849996,0.5300776,0.9288954,0.23576705,3,0.0001,1e-05,100,6,,,172.4834885597229
4,model_type.hyperbolic,activation.dmelu,0.85139996,0.4872045,0.93813366,0.20130627,4,0.0001,1e-05,100,6,,,215.5981888771057
5,model_type.hyperbolic,activation.dmelu,0.8541,0.49497387,0.94635475,0.17573439,5,0.0001,1e-05,100,6,,,258.3830442428589
6,model_type.hyperbolic,activation.dmelu,0.86289996,0.4662113,0.9528415,0.1547455,6,0.0001,1e-05,100,6,,,301.4999806880951
7,model_type.hyperbolic,activation.dmelu,0.8639,0.47909713,0.9584445,0.13693628,7,0.0001,1e-05,100,6,,,344.33811235427856
8,model_type.hyperbolic,activation.dmelu,0.8727,0.45581898,0.9639141,0.12236323,8,0.0001,1e-05,100,6,,,387.18365478515625
9,model_type.hyperbolic,activation.dmelu,0.8793,0.44250196,0.96708244,0.11059982,9,0.0001,1e-05,100,6,,,428.2303366661072
10,model_type.hyperbolic,activation.dmelu,0.88019997,0.44028482,0.9700674,0.09974309,10,0.0001,1e-05,100,6,,,470.96837282180786
11,model_type.hyperbolic,activation.dmelu,0.88009995,0.44759986,0.97315234,0.089882046,11,0.0001,1e-05,100,6,,,514.0624012947083
12,model_type.hyperbolic,activation.dmelu,0.8835,0.4496165,0.97653747,0.08116763,12,0.0001,1e-05,100,6,,,559.0882275104523
13,model_type.hyperbolic,activation.dmelu,0.8832,0.46596962,0.9785386,0.07332477,13,0.0001,1e-05,100,6,,,603.4989850521088
14,model_type.hyperbolic,activation.dmelu,0.8846,0.45920074,0.9810399,0.06587996,14,0.0001,1e-05,100,6,,,647.1708605289459
15,model_type.hyperbolic,activation.dmelu,0.8847,0.471855,0.98259073,0.059854854,15,0.0001,1e-05,100,6,,,690.505782365799
16,model_type.hyperbolic,activation.dmelu,0.88729995,0.47835746,0.984375,0.0538434,16,0.0001,1e-05,100,6,,,734.9276039600372
17,model_type.hyperbolic,activation.dmelu,0.88699996,0.4769912,0.986893,0.047899395,17,0.0001,1e-05,100,6,,,778.8464353084564
18,model_type.hyperbolic,activation.dmelu,0.8831,0.48856255,0.9882604,0.0425485,18,0.0001,1e-05,100,6,,,824.6069004535675
19,model_type.hyperbolic,activation.dmelu,0.8886,0.5039605,0.98891073,0.039367262,19,0.0001,1e-05,100,6,,,870.4442510604858
20,model_type.hyperbolic,activation.dmelu,0.8912,0.4972005,0.99136204,0.033447918,20,0.0001,1e-05,100,6,,,913.3588528633118
21,model_type.hyperbolic,activation.dmelu,0.88909996,0.52335584,0.9914121,0.031359762,21,0.0001,1e-05,100,6,,,956.8052439689636
22,model_type.hyperbolic,activation.dmelu,0.8903,0.5274542,0.99332976,0.026348583,22,0.0001,1e-05,100,6,,,1000.3974275588989
23,model_type.hyperbolic,activation.dmelu,0.8882,0.55234355,0.9940802,0.02404883,23,0.0001,1e-05,100,6,,,1044.3361115455627
24,model_type.hyperbolic,activation.dmelu,0.8889,0.57603663,0.99429697,0.0216483,24,0.0001,1e-05,100,6,,,1088.7605483531952
