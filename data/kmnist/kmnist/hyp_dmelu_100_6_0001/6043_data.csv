,Model,Activation,Test accuracy,Test loss,Train accuracy,Train loss,Epoch,Learning rate,Weight decay,Neurons,Nlayers,Train hyperbolicities,Test hyperbolicities,Time
0,model_type.hyperbolic,activation.dmelu,0.75079995,0.7832818,0.7769477,0.7132773,0,0.0001,1e-05,100,6,,,44.70454740524292
1,model_type.hyperbolic,activation.dmelu,0.7966,0.6542129,0.89030814,0.35599202,1,0.0001,1e-05,100,6,,,85.44038915634155
2,model_type.hyperbolic,activation.dmelu,0.8229,0.58360136,0.9147379,0.27852818,2,0.0001,1e-05,100,6,,,128.7768440246582
3,model_type.hyperbolic,activation.dmelu,0.8372,0.539953,0.9291122,0.23108602,3,0.0001,1e-05,100,6,,,170.6732029914856
4,model_type.hyperbolic,activation.dmelu,0.847,0.51211023,0.9398346,0.1980739,4,0.0001,1e-05,100,6,,,212.248366355896
5,model_type.hyperbolic,activation.dmelu,0.85569996,0.49465454,0.9472052,0.17308928,5,0.0001,1e-05,100,6,,,254.90524554252625
6,model_type.hyperbolic,activation.dmelu,0.86719996,0.4680579,0.9542923,0.15158921,6,0.0001,1e-05,100,6,,,297.6777284145355
7,model_type.hyperbolic,activation.dmelu,0.8698,0.45767057,0.9599453,0.13466899,7,0.0001,1e-05,100,6,,,339.8621475696564
8,model_type.hyperbolic,activation.dmelu,0.87649995,0.4485538,0.9638807,0.12070519,8,0.0001,1e-05,100,6,,,380.9392385482788
9,model_type.hyperbolic,activation.dmelu,0.8767,0.4509415,0.9677495,0.10884008,9,0.0001,1e-05,100,6,,,420.9082431793213
10,model_type.hyperbolic,activation.dmelu,0.8777,0.44004613,0.9714348,0.097198844,10,0.0001,1e-05,100,6,,,462.04739594459534
11,model_type.hyperbolic,activation.dmelu,0.88519996,0.4410526,0.97500336,0.086805165,11,0.0001,1e-05,100,6,,,503.86649322509766
12,model_type.hyperbolic,activation.dmelu,0.8836,0.45204413,0.9773379,0.078812405,12,0.0001,1e-05,100,6,,,547.7022664546967
13,model_type.hyperbolic,activation.dmelu,0.88869995,0.44235322,0.9792389,0.0702372,13,0.0001,1e-05,100,6,,,591.6676645278931
14,model_type.hyperbolic,activation.dmelu,0.8908,0.44641566,0.9810399,0.064711995,14,0.0001,1e-05,100,6,,,633.789350271225
15,model_type.hyperbolic,activation.dmelu,0.88879997,0.4617641,0.9842082,0.056822557,15,0.0001,1e-05,100,6,,,675.9241144657135
16,model_type.hyperbolic,activation.dmelu,0.889,0.4731953,0.9848586,0.052029084,16,0.0001,1e-05,100,6,,,716.9526491165161
17,model_type.hyperbolic,activation.dmelu,0.8925,0.46841398,0.98715985,0.045998346,17,0.0001,1e-05,100,6,,,759.840359210968
18,model_type.hyperbolic,activation.dmelu,0.89019996,0.48811847,0.9891609,0.040310185,18,0.0001,1e-05,100,6,,,802.6830220222473
19,model_type.hyperbolic,activation.dmelu,0.8925,0.49391046,0.9901948,0.03637928,19,0.0001,1e-05,100,6,,,846.8778977394104
20,model_type.hyperbolic,activation.dmelu,0.87979996,0.55606073,0.9912453,0.032574438,20,0.0001,1e-05,100,6,,,889.3836743831635
21,model_type.hyperbolic,activation.dmelu,0.8915,0.52628875,0.9920791,0.029587662,21,0.0001,1e-05,100,6,,,932.3667633533478
22,model_type.hyperbolic,activation.dmelu,0.88989997,0.52940917,0.9939801,0.025191521,22,0.0001,1e-05,100,6,,,976.2108008861542
23,model_type.hyperbolic,activation.dmelu,0.89629996,0.53677297,0.9938467,0.023269674,23,0.0001,1e-05,100,6,,,1018.8732364177704
24,model_type.hyperbolic,activation.dmelu,0.89129996,0.5739887,0.9952141,0.019957997,24,0.0001,1e-05,100,6,,,1061.7116866111755
