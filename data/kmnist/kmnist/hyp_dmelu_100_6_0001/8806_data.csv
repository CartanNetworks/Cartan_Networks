,Model,Activation,Test accuracy,Test loss,Train accuracy,Train loss,Epoch,Learning rate,Weight decay,Neurons,Nlayers,Train hyperbolicities,Test hyperbolicities,Time
0,model_type.hyperbolic,activation.dmelu,0.7349,0.8417335,0.7716449,0.72937673,0,0.0001,1e-05,100,6,,,44.94216966629028
1,model_type.hyperbolic,activation.dmelu,0.7912,0.67844415,0.88663954,0.36903608,1,0.0001,1e-05,100,6,,,87.2843074798584
2,model_type.hyperbolic,activation.dmelu,0.8199,0.5918321,0.9113027,0.28668207,2,0.0001,1e-05,100,6,,,130.1829869747162
3,model_type.hyperbolic,activation.dmelu,0.825,0.5858446,0.9266942,0.23814996,3,0.0001,1e-05,100,6,,,173.46199560165405
4,model_type.hyperbolic,activation.dmelu,0.8515,0.50887835,0.9383171,0.20486598,4,0.0001,1e-05,100,6,,,217.0717315673828
5,model_type.hyperbolic,activation.dmelu,0.85649997,0.48741123,0.9461546,0.17949574,5,0.0001,1e-05,100,6,,,257.8566436767578
6,model_type.hyperbolic,activation.dmelu,0.8645,0.47053906,0.9516909,0.15866323,6,0.0001,1e-05,100,6,,,300.5587856769562
7,model_type.hyperbolic,activation.dmelu,0.8681,0.46033096,0.9580276,0.14144467,7,0.0001,1e-05,100,6,,,346.0685851573944
8,model_type.hyperbolic,activation.dmelu,0.8713,0.45693356,0.96304697,0.12492833,8,0.0001,1e-05,100,6,,,388.62482166290283
9,model_type.hyperbolic,activation.dmelu,0.87369996,0.44586635,0.96719915,0.11274221,9,0.0001,1e-05,100,6,,,432.5209901332855
10,model_type.hyperbolic,activation.dmelu,0.88119996,0.43811655,0.970034,0.10157218,10,0.0001,1e-05,100,6,,,475.487140417099
11,model_type.hyperbolic,activation.dmelu,0.8736,0.46455064,0.97341913,0.09130913,11,0.0001,1e-05,100,6,,,518.8097982406616
12,model_type.hyperbolic,activation.dmelu,0.8803,0.44796127,0.9764541,0.0822973,12,0.0001,1e-05,100,6,,,560.0671832561493
13,model_type.hyperbolic,activation.dmelu,0.88079995,0.46092203,0.9784885,0.074189425,13,0.0001,1e-05,100,6,,,601.9393384456635
14,model_type.hyperbolic,activation.dmelu,0.8849,0.44391686,0.9806397,0.066333085,14,0.0001,1e-05,100,6,,,643.1046142578125
15,model_type.hyperbolic,activation.dmelu,0.8843,0.46467462,0.9831077,0.059242982,15,0.0001,1e-05,100,6,,,684.9538040161133
16,model_type.hyperbolic,activation.dmelu,0.8832,0.48157588,0.9843917,0.053326886,16,0.0001,1e-05,100,6,,,726.5120906829834
17,model_type.hyperbolic,activation.dmelu,0.87979996,0.4986502,0.9869264,0.047302768,17,0.0001,1e-05,100,6,,,768.1126081943512
18,model_type.hyperbolic,activation.dmelu,0.8876,0.48008585,0.9877768,0.04359002,18,0.0001,1e-05,100,6,,,808.8689091205597
19,model_type.hyperbolic,activation.dmelu,0.88699996,0.49871835,0.9899613,0.03755972,19,0.0001,1e-05,100,6,,,851.6045598983765
20,model_type.hyperbolic,activation.dmelu,0.88689995,0.50550044,0.991312,0.032592315,20,0.0001,1e-05,100,6,,,892.8702898025513
21,model_type.hyperbolic,activation.dmelu,0.889,0.51417416,0.9920291,0.030024339,21,0.0001,1e-05,100,6,,,936.0706248283386
22,model_type.hyperbolic,activation.dmelu,0.88879997,0.54127574,0.99374664,0.025299883,22,0.0001,1e-05,100,6,,,978.996762752533
23,model_type.hyperbolic,activation.dmelu,0.88619995,0.55420023,0.99369663,0.023955276,23,0.0001,1e-05,100,6,,,1021.2498230934143
24,model_type.hyperbolic,activation.dmelu,0.8865,0.5594542,0.99449706,0.021285135,24,0.0001,1e-05,100,6,,,1063.9482810497284
